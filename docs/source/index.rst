Welcome to Transactional Machine Learning documentation!
===================================

Transactional Machine Learning : *The Machine Learning Platform for Data Streams*
*Transactional Machine Learning (TML) using Data Streams and AutoML is a platform for building and streaming cloud native solutions using Apache Kafka or Redpanda as the data backbone, with Kubernetes and Docker as core infrastucture components, running on Confluent, AWS, GCP, AZURE,* for advanced machine learning solutions using transactional data to learn from, and provide insights, quickly and continuously to any number of devices and humans in any format!

**TML Is Based On the Belief that "_Fast data requires fast machine learning for fast decision-making_"**. TML gives rise in the industy to a **_Data Stream Scientist_** versus a **_Data Scientist_** in conventional machine learning (CML). 

**TML Book Details Found Here:** [Publisher's site](https://link.springer.com/book/10.1007/978-1-4842-7023-3)

**TML Video:** [Youtube](https://www.youtube.com/watch?v=kXmWE27Q_3o&t=4s)

Apply data preprocessing and auto machine learning to data streams and create transactional machine learning (TML) solutions that are:
 
 **1. frictionless**: require minimal to no human intervention 
 
 **2. elastic**: machine learning solutions that can scale up or down using Kubernetes to control or enhance the number of data streams, algorithms (or machine learning models) and predictions instantly and continuously.

TML is ideal when data are highly erratic (nonlinear) and you want the machine to learn from the **latest** dataset by creating sliding windows of training datasets and auto creating **micro-machine learning models** quickly, that can be easily scaled, managed and the insights used immediately from any device!  **There are many TML use cases such as:**

.. note::

   This project is under active development.

Contents
--------

.. toctree::

   usage 
   api
   tmlbuilds
   
   
